{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:54:15.298220Z","iopub.status.busy":"2024-07-27T04:54:15.297870Z","iopub.status.idle":"2024-07-27T04:54:54.740302Z","shell.execute_reply":"2024-07-27T04:54:54.739373Z","shell.execute_reply.started":"2024-07-27T04:54:15.298191Z"},"scrolled":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n","Collecting transformers\n","  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n","Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.42.3\n","    Uninstalling transformers-4.42.3:\n","      Successfully uninstalled transformers-4.42.3\n","Successfully installed transformers-4.43.3\n","Requirement already satisfied: tf-keras in /opt/conda/lib/python3.10/site-packages (2.15.1)\n","Requirement already satisfied: tensorflow<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tf-keras) (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.26.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.3.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (21.3)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (3.20.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (69.0.3)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15->tf-keras) (2.15.0)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15->tf-keras)\n","  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15->tf-keras) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.26.1)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.32.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.0.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.16,>=2.15->tf-keras) (3.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15->tf-keras) (3.2.2)\n","Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0\n"]}],"source":["# 1. ValueError: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000002686207FD70>\n","# - https://discuss.huggingface.co/t/pretrain-model-not-accepting-optimizer/76209/20\n","\n","!pip install --upgrade transformers\n","!pip install tf-keras\n","import os\n","os.environ['TF_USE_LEGACY_KERAS'] = '1'"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-27T04:54:54.742406Z","iopub.status.busy":"2024-07-27T04:54:54.742096Z","iopub.status.idle":"2024-07-27T04:54:55.137037Z","shell.execute_reply":"2024-07-27T04:54:55.136169Z","shell.execute_reply.started":"2024-07-27T04:54:54.742380Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/dataset_dict.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/validation/state.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/validation/dataset_info.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/validation/data-00000-of-00001.arrow\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/test/state.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/test/dataset_info.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/test/data-00000-of-00001.arrow\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/train/state.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/train/dataset_info.json\n","/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/train/data-00000-of-00001.arrow\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:54:55.140066Z","iopub.status.busy":"2024-07-27T04:54:55.139309Z","iopub.status.idle":"2024-07-27T04:55:12.516817Z","shell.execute_reply":"2024-07-27T04:55:12.516025Z","shell.execute_reply.started":"2024-07-27T04:54:55.140038Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-27 04:54:56.978452: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-27 04:54:56.978576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-27 04:54:57.127786: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.losses import SparseCategoricalCrossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import PolynomialDecay\n","from transformers import AutoTokenizer, DataCollatorWithPadding, TFAutoModelForSequenceClassification\n","from datasets import load_from_disk"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:55:12.519330Z","iopub.status.busy":"2024-07-27T04:55:12.518766Z","iopub.status.idle":"2024-07-27T04:55:13.707947Z","shell.execute_reply":"2024-07-27T04:55:13.706979Z","shell.execute_reply.started":"2024-07-27T04:55:12.519302Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e6bda0be1164285b6d845c69bec62fb","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dc5e660ff194d1f9aa102fa3d84c4d8","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d826f0b1a4b54ab6a876d833c01411eb","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b1d10d7dce14ac2b019dcee64942c9f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["checkpoint = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:55:13.709542Z","iopub.status.busy":"2024-07-27T04:55:13.709149Z","iopub.status.idle":"2024-07-27T04:55:15.082350Z","shell.execute_reply":"2024-07-27T04:55:15.081450Z","shell.execute_reply.started":"2024-07-27T04:55:13.709516Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['questions', 'is_duplicate', 'sentences1', 'sentences2', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 283003\n","    })\n","    test: Dataset({\n","        features: ['questions', 'is_duplicate', 'sentences1', 'sentences2', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 60644\n","    })\n","    validation: Dataset({\n","        features: ['questions', 'is_duplicate', 'sentences1', 'sentences2', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 60643\n","    })\n","})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_dataset = load_from_disk(r\"/kaggle/input/tokenized-quora-duplicates-dataset/tokenized_quora_duplicates_dataset/\")\n","tokenized_dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:55:15.083769Z","iopub.status.busy":"2024-07-27T04:55:15.083461Z","iopub.status.idle":"2024-07-27T04:55:16.212606Z","shell.execute_reply":"2024-07-27T04:55:16.211643Z","shell.execute_reply.started":"2024-07-27T04:55:15.083744Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:410: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n","Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n","             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n","New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n","             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n","  warnings.warn(\n"]}],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n","\n","tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n","    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n","    label_cols=[\"is_duplicate\"],\n","    shuffle=True,\n","    collate_fn=data_collator,\n","    batch_size=8,\n",")\n","\n","tf_validation_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(\n","    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n","    label_cols=[\"is_duplicate\"],\n","    shuffle=False,\n","    collate_fn=data_collator,\n","    batch_size=8,\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:55:16.214545Z","iopub.status.busy":"2024-07-27T04:55:16.214089Z","iopub.status.idle":"2024-07-27T04:55:16.219930Z","shell.execute_reply":"2024-07-27T04:55:16.219035Z","shell.execute_reply.started":"2024-07-27T04:55:16.214495Z"},"trusted":true},"outputs":[],"source":["num_epochs = 5\n","\n","num_training_steps = len(tf_train_dataset) * num_epochs\n","\n","lr_scheduler = PolynomialDecay(\n","    initial_learning_rate=5e-5,\n","    end_learning_rate=0.0,\n","    decay_steps=num_training_steps,\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T04:55:16.221409Z","iopub.status.busy":"2024-07-27T04:55:16.221126Z","iopub.status.idle":"2024-07-27T09:37:34.268898Z","shell.execute_reply":"2024-07-27T09:37:34.268086Z","shell.execute_reply.started":"2024-07-27T04:55:16.221386Z"},"scrolled":true,"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca865bdec5794941909b4f9b2ff60134","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","WARNING: AutoGraph could not transform <function infer_framework at 0x789e2f9d5bd0> and will run it as-is.\n","Cause: for/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1722056202.030455     119 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["35376/35376 [==============================] - 3501s 96ms/step - loss: 0.3498 - accuracy: 0.8403 - val_loss: 0.3004 - val_accuracy: 0.8679\n","Epoch 2/5\n","35376/35376 [==============================] - 3333s 94ms/step - loss: 0.2569 - accuracy: 0.8912 - val_loss: 0.2956 - val_accuracy: 0.8818\n","Epoch 3/5\n","35376/35376 [==============================] - 3352s 95ms/step - loss: 0.1789 - accuracy: 0.9291 - val_loss: 0.2793 - val_accuracy: 0.8898\n","Epoch 4/5\n","35376/35376 [==============================] - 3372s 95ms/step - loss: 0.1071 - accuracy: 0.9604 - val_loss: 0.3125 - val_accuracy: 0.8940\n","Epoch 5/5\n","35376/35376 [==============================] - 3375s 95ms/step - loss: 0.0536 - accuracy: 0.9813 - val_loss: 0.4196 - val_accuracy: 0.8945\n"]},{"data":{"text/plain":["<tf_keras.src.callbacks.History at 0x789e100918d0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n","opt = Adam(learning_rate=lr_scheduler)\n","\n","model.compile(\n","    loss=SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=opt,\n","    metrics=[\"accuracy\"],\n",")\n","\n","model.fit(\n","    tf_train_dataset,\n","    validation_data=tf_validation_dataset,\n","    epochs=num_epochs,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-27T09:37:35.508846Z","iopub.status.busy":"2024-07-27T09:37:35.508577Z","iopub.status.idle":"2024-07-27T09:37:36.771653Z","shell.execute_reply":"2024-07-27T09:37:36.770644Z","shell.execute_reply.started":"2024-07-27T09:37:35.508822Z"},"trusted":true},"outputs":[],"source":["model.save_pretrained(\"quora_duplicate_question_detector\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5450651,"sourceId":9041154,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
